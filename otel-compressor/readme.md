## Otel Compressor: A prototype implementation of TraceZip through OpenTelemetry Collector

## TL;DR

- Set Parameters in `./config` like:

  - `attr_limit`
  - `srt_threshold`
  - batch size, parameter of component batch[which is a processor]

  PROPERLY
- You can use `docker-compose up -d` to setup agent-gateway architecture otel compressor.
- Send spans to `localhost:4318`
- You can check CR rate(compression rate) and throughput through `docker logs [id_of_compressor_agent]`.
- You can change the config file in `./config` to change arguments or relay spans.

## Introduction

The OTEL compressor is a prototype system implementing the algorithm proposed in TraceZip on OpenTelemetry.

The OTEL compressor provides compression and decompression plugins for OpenTelemetry.

Use command `go work sync` to synchronize all modules.

Compile the OTEL collector with our compression and decompression plugins using `go build ./otelcol-dev`, or use our provided Dockerfile to package the images.

**Also you can use the docker image that we built:`angrychow1/otel-compressor:latest`.**

For usage and configuration of the OpenTelemetry collector and plugins, refer to the [OpenTelemetry official documentation](https://opentelemetry.io/docs/collector/configuration/).

The configuration file for the plugin is as follows:

```yaml
exporters:
  prefix_compressed_exporter:
    sample_buffer: 1024
    srt_threshold: 10000
    no_tracezip: false
    attr_limit: 100
    calc_zip_rate: false
    enable_gzip: true
    endpoint: http://127.0.0.1:14318
    tls:
      insecure: true
```

- `sample_buffer` determines the range of sampled span attribute frequency information.
- `srt_threshold` limits the total number of trie paths when synchronizing spans information. If the sum of all paths in the current trie exceeds `srt_threshold`, it triggers a trie reconstruction.
- `no_tracezip` determines whether compressor use TraceZip algorithm or not.
- `attr_limit` limits the number of attributes that can enter the non-leaf nodes of the trie. Attributes with option values greater than `attr_limit` will not be allowed into the trie for compression and will not be synchronized with the hash dictionary.
- `calc_zip_rate` is used to calculate the compression gain of our plugin compared to general compression algorithms.
- `enable_gzip` enables gzip encoding for transmission.
- `endpoint` specifies the location of the receiver.

```yaml
receivers:
  prefix_compressed_receiver: 
    protocols:
      http:
        endpoint: localhost:14318
```

The receiver only needs to configure the listening host:port.

### How to use

You can simply send formatted [span data](https://zenodo.org/records/14302089) to compressor endpoint. (You may need write a scripts to send it), using scripts in directory `./wrk`.

If you want to send the dataset provided by us to verify the experiment, please remember to select the span data with the same service instance name (infered by a attribute in `resource_spans.resource.attributes[]` called `host.name`) from the dataset for sending. We distinguished it in new version datasets.

We provide `config_export.yaml` and `config_receive` as examples.

In MicroSerivce Cluster instrumented with docker, we recommend a 'agent/gateway' compose method. First, relay spans generated by a service to agent, exporter of agent using our compressor. Then agent send it to gateway, gateway decompress it and pass it to traces/metrics/logs backend platform like Jaeger. At this circumstance, we suggest that for every agent, it should be deployed at the same instance of its mircoservice, and gateway should be deployed separately.

For example, we instrument it on basic-service, one of micro-service of TrainTicket Benchmark:

1. Build basic-service, edit its opentelemetry sdk yaml, relay spans to agent.
2. `config_agent.yaml` is just like `config_export.yaml`
3. `config_gateway.yaml` is just like `config_receive.yaml`
4. `docker-compose.yml` should be like:

```
...
basic-compressor:
  image: compressor
  deploy:
    restart_policy:
      condition: on-failure
  networks:
    - my-network
  volumes:
    - ./compressor-agent.yml:/app/agent-config.yml
  command: ["--config", "agent-config.yml"]
  depends_on:
    - compressor-gateway

compressor-agent:
  image: compressor
  deploy:
      restart_policy:
        condition: on-failure
  networks:
      - my-network
  volumes:
      - ./compressor-agent.yml:/app/agent-config.yml
  command: ["--config", "agent-config.yml"]
  depends_on:
      - compressor-gateway
...
```

the configuration is similar for k8s cluster.

Specifically, if you want to send the dataset we provided, you need to categorize all the span data by hostname and send them accordingly. You can find the hostname in the attributes of the resource_spans in each spans file.
